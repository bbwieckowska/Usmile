% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/2_funtion_UScalc_mdl.R
\name{UScalc_mdl}
\alias{UScalc_mdl}
\title{Calculate U-smile coefficients for model comparison (based on models)}
\usage{
UScalc_mdl(ref_model, new_model, y_coef, dataset = NULL, testing = FALSE)
}
\arguments{
\item{ref_model}{Reference model object (glm or randomForest)}

\item{new_model}{New model object to compare (glm or randomForest)}

\item{y_coef}{Type of coefficient to calculate:
\itemize{
\item "rLR" - Relative Likelihood Ratio
\item "BA" - Brier Alteration (average absolute change)
\item "RB" - Relative Brier (relative change)
}}

\item{dataset}{#' @param dataset Dataset used to prepare data for the models.
\itemize{
\item If \code{testing = TRUE}, a test dataset must be provided (required).
\item If \code{testing = FALSE}, the argument can be:
\itemize{
\item \code{NULL} if the model stores its own training data (e.g., \code{glm}, \code{randomForest}),
\item the training dataset if the model does not keep training data internally
(e.g., \code{ranger}, \code{e1071}, \code{xgboost}, \code{nnet}, \code{naive_bayes}, tidymodels).
This allows the function to work consistently with both training and test data.
}
}}

\item{testing}{Logical indicating whether to use test data (TRUE) or training data (FALSE)}
}
\value{
A list containing:
\itemize{
\item results - Data frame with detailed comparison metrics
\item plot_data - Data for visualization (used by USplot)
}
}
\description{
Computes USMILE (User-centric Statistical Measures for Interpretable Learning Explanations)
coefficients for comparing two predictive models.
}
\examples{
\dontrun{
# Load Heart Disease datasets
data(heart_disease)
data(heart_disease_train)
data(heart_disease_test)

# Compare two logistic regression models
model_glm_ref <- glm(disease ~ age + sex + bp + chol, data = heart_disease_train, family = "binomial")
model_glm_new <- glm(disease ~ age + sex + bp + chol + cp, data = heart_disease_train, family = "binomial")

# Calculate rLR coefficients on training and test data
train_results_rLR <- UScalc_mdl(model_glm_ref, model_glm_new, y_coef = "rLR",
                         dataset = NULL, testing = FALSE)
test_results_rLR <- UScalc_mdl(model_glm_ref, model_glm_new, y_coef = "rLR",
                         dataset = heart_disease_test, testing = TRUE)

# Calculate BA coefficients on training data
train_results_BA <- UScalc_mdl(model_glm_ref, model_glm_new, y_coef = "BA",
                        dataset = NULL, testing = FALSE)
# Calculate RB coefficients on training data
train_results_RB <- UScalc_mdl(model_glm_ref, model_glm_new, y_coef = "RB",
                        dataset = NULL, testing = FALSE)

# Compare Random Forest to logistic regression
# (both models must be built based on the same variables)
model_fr_ref <- randomForest::randomForest(disease ~ age + sex + bp + chol, data = heart_disease_train)
train_results_rf_vs_glm <- UScalc_mdl(model_glm_ref, model_rf_ref, y_coef = "rLR",
                               dataset = NULL, testing = FALSE)
}

}
